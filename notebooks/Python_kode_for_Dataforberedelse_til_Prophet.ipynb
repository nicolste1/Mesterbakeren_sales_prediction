{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolste1/Mesterbakeren_sales_prediction/blob/main/Python_kode_for_Dataforberedelse_til_Prophet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5tFepz-dQwC"
      },
      "source": [
        "# Ting å legge til\n",
        "\n",
        "*   Ordentlig bruk av holyday funksjon DONE\n",
        "*   Klare å mestre det ukentlige variasjonene HALVEIS\n",
        "*   Skole fri DONE\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "yQg5iz8Hckao"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def prepare_sales_data(file_path, sheet_name, verbose=True):\n",
        "    \"\"\"\n",
        "    Prepares sales data from an Excel file for Prophet modeling.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the Excel file.\n",
        "        sheet_name (str): The name of the sheet to read from.\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The prepared DataFrame with 'ds', 'y', and 'Butikk_ID' columns,\n",
        "                      or an empty DataFrame if an error occurred.\n",
        "    \"\"\"\n",
        "    df_full_raw = None\n",
        "    try:\n",
        "        df_full_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
        "        if verbose:\n",
        "            print(f\"Excel file '{file_path}' loaded.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: '{file_path}' not found.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'Butikk_ID'])\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the Excel file: {e}\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'Butikk_ID'])\n",
        "\n",
        "    if df_full_raw is not None and not df_full_raw.empty:\n",
        "        # --- Identify date columns and sales data rows ---\n",
        "        # Assuming dates are in the SECOND row (index 1), from column 3 onwards.\n",
        "        # Assuming store data starts from row 4 (index 3) onwards.\n",
        "        # Assuming the first store data is in row 5 (index 4) in the raw data.\n",
        "\n",
        "        # --- Manual Date Range Creation ---\n",
        "        # Define start and end dates manually based on the file content structure\n",
        "        # Assuming the start date is in cell D2 (column 3, row 1) and end date in cell BW2 (column 1324, row 1)\n",
        "        # Based on the printout, the first date is in column 3, row 1 (index 1), and the last date is in column 1324, row 1 (index 1)\n",
        "        # Let's try to extract the start and end dates from the raw data if available, otherwise use hardcoded fallbacks.\n",
        "        start_date_from_file = None\n",
        "        end_date_from_file = None\n",
        "\n",
        "        try:\n",
        "             # Attempt to read the start date from the specified cell (D2 -> iloc[1, 3])\n",
        "            raw_start_date_value = df_full_raw.iloc[1, 3]\n",
        "            # Attempt to read the end date from the last date column (iloc[1, -1])\n",
        "            raw_end_date_value = df_full_raw.iloc[1, -1]\n",
        "\n",
        "            # Try to parse these values into datetime objects\n",
        "            if pd.notna(raw_start_date_value):\n",
        "                # Handle potential datetime objects or strings\n",
        "                if isinstance(raw_start_date_value, pd.Timestamp):\n",
        "                    start_date_from_file = raw_start_date_value.strftime('%Y-%m-%d')\n",
        "                else:\n",
        "                    # Try parsing as string, assuming day/month/year format\n",
        "                    try:\n",
        "                        start_date_from_file = pd.to_datetime(str(raw_start_date_value).split(' ')[0], format='%d/%m/%Y').strftime('%Y-%m-%d')\n",
        "                    except:\n",
        "                         print(f\"Warning: Could not parse start date '{raw_start_date_value}'. Using fallback.\") # Always print warnings\n",
        "                         start_date_from_file = '2021-12-09' # Fallback\n",
        "\n",
        "            if pd.notna(raw_end_date_value):\n",
        "                 if isinstance(raw_end_date_value, pd.Timestamp):\n",
        "                    end_date_from_file = raw_end_date_value.strftime('%Y-%m-%d')\n",
        "                 else:\n",
        "                    try:\n",
        "                        end_date_from_file = pd.to_datetime(str(raw_end_date_value).split(' ')[0], format='%d/%m/%Y').strftime('%Y-%m-%d')\n",
        "                    except:\n",
        "                         print(f\"Warning: Could not parse end date '{raw_end_date_value}'. Using fallback.\") # Always print warnings\n",
        "                         end_date_from_file = '2025-07-22' # Fallback\n",
        "\n",
        "        except IndexError:\n",
        "            print(\"Warning: Could not access expected date cells. Using fallback dates.\") # Always print warnings\n",
        "            start_date_from_file = '2021-12-09'\n",
        "            end_date_from_file = '2025-07-22'\n",
        "        except Exception as e:\n",
        "             print(f\"An unexpected error occurred while trying to read dates: {e}. Using fallback dates.\") # Always print errors\n",
        "             start_date_from_file = '2021-12-09'\n",
        "             end_date_from_file = '2025-07-22'\n",
        "\n",
        "\n",
        "        start_date_manual = start_date_from_file if start_date_from_file else '2021-12-09'\n",
        "        end_date_manual = end_date_from_file if end_date_from_file else '2025-07-22'\n",
        "\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Creating date range from {start_date_manual} to {end_date_manual}...\")\n",
        "        full_date_range = pd.date_range(start=start_date_manual, end=end_date_manual, freq='D')\n",
        "        full_date_range_df = pd.DataFrame({'ds': full_date_range})\n",
        "        if verbose:\n",
        "            print(f\"Created date range with {len(full_date_range_df)} days.\")\n",
        "\n",
        "\n",
        "        # --- Extract raw sales data for the first store ---\n",
        "        if len(df_full_raw) > 4: # Check that there are enough rows for store data\n",
        "            first_store_row = df_full_raw.iloc[4] # Get the row for the first store\n",
        "            selected_store_id = first_store_row.iloc[1] # Store ID is in column 1 (index 1)\n",
        "\n",
        "            # Sales data starts from original column 3 (index 3 in the raw DataFrame)\n",
        "            sales_data_for_selected_store_raw = first_store_row.iloc[3:]\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Extracted {len(sales_data_for_selected_store_raw)} raw sales data points for store ID {selected_store_id}.\")\n",
        "\n",
        "            # Convert to numeric, set errors to NaN, fill NaN with 0\n",
        "            numeric_sales_data = pd.to_numeric(sales_data_for_selected_store_raw, errors='coerce').fillna(0)\n",
        "\n",
        "            # IMPORTANT: Reset the index of the sales data so it matches the date range's RangeIndex\n",
        "            numeric_sales_data = numeric_sales_data.reset_index(drop=True)\n",
        "\n",
        "            # --- Combine date range and sales data ---\n",
        "            if len(numeric_sales_data) != len(full_date_range_df):\n",
        "                print(f\"Critical Warning: Number of sales data points ({len(numeric_sales_data)}) does NOT match the number of days in the date range ({len(full_date_range_df)}). Cannot proceed with data prep.\") # Always print warnings\n",
        "                return pd.DataFrame(columns=['ds', 'y', 'Butikk_ID'])\n",
        "            else:\n",
        "                df_prepared = pd.DataFrame({\n",
        "                    'ds': full_date_range_df['ds'],\n",
        "                    'y': numeric_sales_data\n",
        "                })\n",
        "\n",
        "            # --- Add Store_ID ---\n",
        "            df_prepared['Butikk_ID'] = selected_store_id\n",
        "\n",
        "            # --- Validation ---\n",
        "            if verbose:\n",
        "                print(\"\\nPrepared DataFrame (df_prepared) with manual date range:\")\n",
        "                print(df_prepared.head())\n",
        "                print(\"\\nInformation about df_prepared:\")\n",
        "                df_prepared.info()\n",
        "                print(\"\\nChecking for missing values in df_prepared:\")\n",
        "                print(df_prepared.isnull().sum())\n",
        "\n",
        "\n",
        "            if verbose:\n",
        "                print(\"\\n'df_prepared' is now ready with manual date range.\")\n",
        "            return df_prepared\n",
        "\n",
        "        else:\n",
        "            print(\"Error: 'df_full_raw' does not have enough rows to extract store data.\") # Always print errors\n",
        "            return pd.DataFrame(columns=['ds', 'y', 'Butikk_ID'])\n",
        "\n",
        "    else:\n",
        "        print(\"Data preparation could not be completed due to errors loading the file or empty raw data.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'Butikk_ID'])\n",
        "\n",
        "\n",
        "\n",
        "# --- Main part of the script ---\n",
        "# print(\"Starting data preparation using the function...\")\n",
        "# df_prepared = prepare_sales_data('colab/MB salg.xlsx', 'Ark1')\n",
        "\n",
        "# if not df_prepared.empty:\n",
        "#     print(\"\\nData preparation function completed successfully.\")\n",
        "#     print(\"\\nFirst 5 rows of df_prepared:\")\n",
        "#     display(df_prepared.head())\n",
        "#     print(\"\\nLast 5 rows of df_prepared:\")\n",
        "#     display(df_prepared.tail())\n",
        "#     print(\"\\nInformation about df_prepared:\")\n",
        "#     display(df_prepared.info())\n",
        "# else:\n",
        "#     print(\"\\nData preparation function failed to return a valid DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e48c879d",
        "outputId": "d54683a4-9fed-483e-fb3e-07063c260de0"
      },
      "outputs": [],
      "source": [
        "def split_data(df):\n",
        "    \"\"\"\n",
        "    Splits a DataFrame into training and testing sets based on the year 2025.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame with a 'ds' column.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two DataFrames: (train_df, test_df).\n",
        "               train_df contains data before 2025, test_df contains data for 2025 onwards.\n",
        "    \"\"\"\n",
        "    # Ensure the 'ds' column is in datetime format\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df['ds']):\n",
        "        df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
        "        # Drop rows where date conversion failed\n",
        "        df.dropna(subset=['ds'], inplace=True)\n",
        "\n",
        "    train_df = df[df['ds'].dt.year < 2025].copy()\n",
        "    test_df = df[df['ds'].dt.year >= 2025].copy()\n",
        "    return train_df, test_df\n",
        "\n",
        "# Split the data using the defined function\n",
        "train_df, test_df = split_data(df_prepared)\n",
        "\n",
        "# Print the number of rows in both dataframes to confirm the split\n",
        "print(f\"Number of rows in the training set (before 2025): {len(train_df)}\")\n",
        "print(f\"Number of rows in the test set (2025 and later): {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVNmVnXZnVJy",
        "outputId": "4b402618-535c-4dd0-e715-31dcabdb2500"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8ba34a6a"
      },
      "outputs": [],
      "source": [
        "from prophet import Prophet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_prophet_model(train_df):\n",
        "    \"\"\"\n",
        "    Initializes and trains a Prophet model. Dynamically adds regressors based on\n",
        "    columns present in the training DataFrame (excluding 'ds' and 'y').\n",
        "\n",
        "    Args:\n",
        "        train_df (pd.DataFrame): The training DataFrame with 'ds', 'y' columns,\n",
        "                                 and potentially other regressor columns.\n",
        "\n",
        "    Returns:\n",
        "        Prophet: The trained Prophet model.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Holiday Generation\n",
        "    start_year_data = 2020\n",
        "    end_year_forecast = 2028\n",
        "\n",
        "    sample_custom_holidays_list = [\n",
        "    ]\n",
        "    if not sample_custom_holidays_list:\n",
        "        print(\"Warning: sample_custom_holidays_list is empty. Skipping custom holidays.\")\n",
        "    else:\n",
        "        sample_custom_holidays_df = pd.DataFrame(sample_custom_holidays_list)\n",
        "        sample_custom_holidays_df['ds'] = pd.to_datetime(sample_custom_holidays_df['ds'])\n",
        "        norwegian_holidays_with_custom = generate_norwegian_holidays(start_year_data, end_year_forecast, sample_custom_holidays_df)\n",
        "\n",
        "    norwegian_holidays_with_custom = generate_norwegian_holidays(start_year_data, end_year_forecast)\n",
        "    # End Holiday Generation\n",
        "\n",
        "\n",
        "    prophet_model = Prophet(\n",
        "        holidays=norwegian_holidays_with_custom,\n",
        "        weekly_seasonality=False, # No weekly seasonality\n",
        "    changepoint_prior_scale=0.08,     # Økt fleksibilitet for trend\n",
        "    seasonality_prior_scale=15        # Økt fleksibilitet for sesongvariasjoner\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Identify regressor columns (all columns except 'ds' and 'y' and 'Butikk_ID')\n",
        "    regressor_cols = [col for col in train_df.columns if col not in ['ds', 'y', 'Butikk_ID']]\n",
        "\n",
        "    # Add each identified regressor to the Prophet model\n",
        "    for regressor in regressor_cols:\n",
        "        # Specify mode='multiplicative' for weekday regressors\n",
        "        if regressor in ['is_monday', 'is_tuesday', 'is_wednesday', 'is_thursday', 'is_friday', 'is_saturday', 'is_sunday']:\n",
        "             mode = 'multiplicative'\n",
        "             print(f\"Added regressor: {regressor} with mode='multiplicative'\")\n",
        "        else:\n",
        "            # Use default additive mode for other regressors (weather, holiday)\n",
        "            mode = 'additive'\n",
        "            print(f\"Added regressor: {regressor} with mode='additive'\")\n",
        "\n",
        "        prophet_model.add_regressor(regressor, mode=mode)\n",
        "\n",
        "\n",
        "    # Select the columns needed for training (ds, y, and all identified regressors)\n",
        "    cols_for_training = ['ds', 'y'] + regressor_cols\n",
        "\n",
        "    # Fit the model with the selected columns\n",
        "    prophet_model.fit(train_df[cols_for_training])\n",
        "    print(\"Prophet model fitted with regressors.\")\n",
        "\n",
        "    return prophet_model\n",
        "\n",
        "def generate_prophet_predictions(prophet_model, test_df):\n",
        "    \"\"\"\n",
        "    Generates predictions for a test period using a trained Prophet model.\n",
        "    Includes regressors present in the test DataFrame (excluding 'ds' and 'y').\n",
        "\n",
        "    Args:\n",
        "        prophet_model (Prophet): The trained Prophet model.\n",
        "        test_df (pd.DataFrame): The test DataFrame with 'ds' column\n",
        "                                and potentially other regressor columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with the forecast.\n",
        "    \"\"\"\n",
        "    # Create the future dataframe based on the length of the test_df\n",
        "    future = prophet_model.make_future_dataframe(periods=len(test_df), freq='D', include_history=False) # Only include future dates\n",
        "\n",
        "    # Identify regressor columns in the test DataFrame (all except 'ds', 'y', 'Butikk_ID')\n",
        "    regressor_cols_test = [col for col in test_df.columns if col not in ['ds', 'y', 'Butikk_ID']]\n",
        "\n",
        "    # Ensure the future dataframe has the regressor columns needed for prediction\n",
        "    # We need to merge the regressor information from the test_df onto the future dataframe.\n",
        "    # Only merge the identified regressor columns and 'ds'\n",
        "    cols_to_merge = ['ds'] + regressor_cols_test\n",
        "    future = pd.merge(future, test_df[cols_to_merge], on='ds', how='left')\n",
        "\n",
        "    # Handle potential NaNs in regressor columns in the future dataframe\n",
        "    # For simplicity, fill with 0 or a relevant value if prediction fails due to NaNs\n",
        "    for regressor in regressor_cols_test:\n",
        "         if future[regressor].isnull().any():\n",
        "             # Simple fill with 0, but consider a more sophisticated imputation if needed\n",
        "             print(f\"Warning: NaN values found in regressor '{regressor}' in the future dataframe. Filling with 0.\")\n",
        "             future[regressor].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "    forecast = prophet_model.predict(future)\n",
        "    return forecast\n",
        "\n",
        "# Example usage (assuming train_df and test_df exist)\n",
        "# print(\"Starting Prophet model training and prediction...\")\n",
        "# try:\n",
        "#     # Ensure train_df and test_df have the regressors added by add_regressors\n",
        "#     # Assuming add_regressors has been called before this point\n",
        "#     prophet_model_trained = train_prophet_model(train_df)\n",
        "#     forecast_result = generate_prophet_predictions(prophet_model_trained, test_df)\n",
        "#\n",
        "#     print(\"\\nProphet model training and prediction completed.\")\n",
        "#     print(\"\\nFirst 5 rows of forecast_result:\")\n",
        "#     display(forecast_result[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())\n",
        "#\n",
        "# except NameError:\n",
        "#     print(\"Error: train_df or test_df is not defined. Run data preparation and splitting first.\")\n",
        "# except KeyError as e:\n",
        "#      print(f\"Error: Missing required column in train_df or test_df for training/prediction - {e}\")\n",
        "# except Exception as e:\n",
        "#      print(f\"An error occurred during Prophet model training or prediction: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7aff1822"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_prophet_results(prophet_model, forecast, test_df, verbose=True):\n",
        "    \"\"\"\n",
        "    Visualizes the Prophet forecast and overlays the actual test data.\n",
        "\n",
        "    Args:\n",
        "        prophet_model (Prophet): The trained Prophet model.\n",
        "        forecast (pd.DataFrame): The forecast DataFrame from Prophet.\n",
        "        test_df (pd.DataFrame): The test DataFrame with actual values.\n",
        "        verbose (bool): If True, show the plot. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        None. Displays the plot if verbose is True.\n",
        "    \"\"\"\n",
        "    # Add a check to ensure necessary variables are defined before plotting\n",
        "    if 'prophet_model' not in locals() and 'prophet_model' not in globals():\n",
        "        print(\"Error: Prophet model is not defined. Cannot visualize results.\") # Always print errors\n",
        "        return\n",
        "    if 'forecast' not in locals() and 'forecast' not in globals():\n",
        "         print(\"Error: Forecast DataFrame is not defined. Cannot visualize results.\") # Always print errors\n",
        "         return\n",
        "    if 'test_df' not in locals() and 'test_df' not in globals():\n",
        "         print(\"Error: Test DataFrame is not defined. Cannot visualize results.\") # Always print errors\n",
        "         return\n",
        "\n",
        "\n",
        "    fig = prophet_model.plot(forecast)\n",
        "    plt.scatter(test_df['ds'], test_df['y'], color='red', label='Actuals')\n",
        "    plt.title('Prophet Forecast vs. Actuals')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Sales')\n",
        "    plt.legend()\n",
        "    if verbose:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f17c273"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_forecast_vs_actuals(test_df, forecast_df, verbose=True):\n",
        "    \"\"\"\n",
        "    Visualizes the Prophet forecast and actual test data on a separate plot.\n",
        "    Also visualizes forecast components if a Prophet model is available.\n",
        "\n",
        "    Args:\n",
        "        test_df (pd.DataFrame): The test DataFrame with actual 'y' values.\n",
        "        forecast_df (pd.DataFrame): The forecast DataFrame (either original or coregated)\n",
        "                                   with 'ds' and prediction column ('yhat' or 'coregated_yhat').\n",
        "        verbose (bool): If True, show the plots. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        None. Displays the plots if verbose is True.\n",
        "    \"\"\"\n",
        "    # Determine the prediction column name and confidence interval columns\n",
        "    if 'coregated_yhat' in forecast_df.columns:\n",
        "        prediction_col = 'coregated_yhat'\n",
        "        # Note: Coregated predictions don't inherently have their own confidence intervals\n",
        "        # We can choose to plot the original 'yhat_lower'/'yhat_upper' or skip the fill_between\n",
        "        yhat_lower_col = 'yhat_lower' if 'yhat_lower' in forecast_df.columns else None\n",
        "        yhat_upper_col = 'yhat_upper' if 'yhat_upper' in forecast_df.columns else None\n",
        "        label_prefix = 'Coregated ' # Label prefix for coregated plot\n",
        "    elif 'yhat' in forecast_df.columns:\n",
        "        prediction_col = 'yhat'\n",
        "        yhat_lower_col = 'yhat_lower' if 'yhat_lower' in forecast_df.columns else None\n",
        "        yhat_upper_col = 'yhat_upper' if 'yhat_upper' in forecast_df.columns else None\n",
        "        label_prefix = 'Prophet ' # Label prefix for original forecast\n",
        "    else:\n",
        "        print(\"Error: Forecast DataFrame does not contain 'yhat' or 'coregated_yhat' column for visualization.\") # Always print errors\n",
        "        return\n",
        "\n",
        "\n",
        "    # Ensure forecast DataFrame is filtered to the test period for plotting\n",
        "    # We can use the 'ds' column from the test_df to filter the forecast\n",
        "    # Select necessary columns for plotting\n",
        "    cols_to_select = ['ds', prediction_col]\n",
        "    if yhat_lower_col: cols_to_select.append(yhat_lower_col)\n",
        "    if yhat_upper_col: cols_to_select.append(yhat_upper_col)\n",
        "    # Also include original yhat if coregated for potential comparison plot\n",
        "    if prediction_col == 'coregated_yhat' and 'yhat' in forecast_df.columns:\n",
        "        cols_to_select.append('yhat')\n",
        "\n",
        "\n",
        "    forecast_test_period = forecast_df[forecast_df['ds'].isin(test_df['ds'])][cols_to_select].copy()\n",
        "\n",
        "\n",
        "    if forecast_test_period.empty:\n",
        "        print(\"Error: No overlapping dates found between test data and forecast for visualization.\") # Always print errors\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(test_df['ds'], test_df['y'], label='Actuals', color='red', marker='o', linestyle='None')\n",
        "    plt.plot(forecast_test_period['ds'], forecast_test_period[prediction_col], label=f'{label_prefix}Forecast', color='blue')\n",
        "\n",
        "    # Plot original yhat if coregated for comparison\n",
        "    if prediction_col == 'coregated_yhat' and 'yhat' in forecast_test_period.columns:\n",
        "        plt.plot(forecast_test_period['ds'], forecast_test_period['yhat'], label='Original Prophet Forecast', color='green', linestyle='--')\n",
        "\n",
        "\n",
        "    # Plot confidence interval if available\n",
        "    if yhat_lower_col and yhat_upper_col and yhat_lower_col in forecast_test_period.columns and yhat_upper_col in forecast_test_period.columns:\n",
        "         plt.fill_between(forecast_test_period['ds'], forecast_test_period[yhat_lower_col], forecast_test_period[yhat_upper_col], color='blue', alpha=0.2, label='Confidence Interval')\n",
        "    else:\n",
        "        if verbose:\n",
        "             print(\"Note: Confidence intervals not available for plotting (e.g., for coregated forecast).\") # Print note if verbose\n",
        "\n",
        "\n",
        "    plt.title(f'{label_prefix}Forecast vs. Actual Test Data')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Sales')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    if verbose:\n",
        "        plt.show()\n",
        "\n",
        "    # Add plot for components (only for original Prophet model forecast)\n",
        "    if verbose:\n",
        "        # Check if the input forecast_df is the original Prophet forecast (likely has 'yhat' and components)\n",
        "        # or if the original prophet_model is available in the global scope\n",
        "        if prediction_col == 'yhat' and ('prophet_model' in globals() and prophet_model is not None):\n",
        "            print(\"\\nVisualizing forecast components...\")\n",
        "            prophet_model.plot_components(forecast_df) # Use the full forecast_df for components plot\n",
        "            plt.show()\n",
        "        elif prediction_col == 'coregated_yhat':\n",
        "             if verbose:\n",
        "                print(\"\\nSkipping component plot for coregated forecast (components are from the original model).\") # Print note if verbose\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"Warning: Prophet model or original forecast not found. Cannot plot components.\") # Always print warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ff84e7f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_prophet_model(test_df, forecast_df, verbose=True):\n",
        "    \"\"\"\n",
        "    Evaluates the Prophet model's predictions against actual test data.\n",
        "\n",
        "    Args:\n",
        "        test_df (pd.DataFrame): The test DataFrame with actual 'y' values.\n",
        "        forecast_df (pd.DataFrame): The forecast DataFrame (either original or coregated)\n",
        "                                    with 'ds' and prediction column ('yhat' or 'coregated_yhat').\n",
        "        verbose (bool): If True, print evaluation metrics and explanations. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        None. Prints evaluation metrics to the console.\n",
        "    \"\"\"\n",
        "    # Determine the prediction column name\n",
        "    if 'coregated_yhat' in forecast_df.columns:\n",
        "        prediction_col = 'coregated_yhat'\n",
        "    elif 'yhat' in forecast_df.columns:\n",
        "        prediction_col = 'yhat'\n",
        "    else:\n",
        "        print(\"Error: Forecast DataFrame does not contain 'yhat' or 'coregated_yhat' column for evaluation.\") # Always print errors\n",
        "        return\n",
        "\n",
        "    # Ensure forecast DataFrame is filtered to the test period for merging\n",
        "    # and that we are only comparing dates present in the test set.\n",
        "    # Select only the date and the identified prediction column from the forecast_df\n",
        "    forecast_test_period = forecast_df[forecast_df['ds'].isin(test_df['ds'])][['ds', prediction_col]].copy()\n",
        "\n",
        "\n",
        "    # Merge actuals with forecast based on date\n",
        "    # Use the determined prediction_col for merging\n",
        "    performance_df = pd.merge(test_df[['ds', 'y']], forecast_test_period, on='ds', how='inner')\n",
        "\n",
        "    if performance_df.empty:\n",
        "        print(\"Error: No overlapping dates found between test data and forecast for evaluation.\") # Always print errors\n",
        "        return\n",
        "\n",
        "    # --- Handle NaN values before calculating metrics ---\n",
        "    # Drop rows where either actual ('y') or predicted ('yhat' or 'coregated_yhat') values are NaN\n",
        "    initial_rows = len(performance_df)\n",
        "    performance_df.dropna(subset=['y', prediction_col], inplace=True)\n",
        "    rows_after_dropna = len(performance_df)\n",
        "\n",
        "    if rows_after_dropna < initial_rows:\n",
        "        print(f\"Warning: Dropped {initial_rows - rows_after_dropna} rows with NaN values in 'y' or '{prediction_col}' before calculating evaluation metrics.\") # Always print warnings\n",
        "        if performance_df.empty:\n",
        "            print(\"Error: No valid data points remaining after dropping NaNs for evaluation.\") # Always print errors\n",
        "            return\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(performance_df['y'], performance_df[prediction_col])\n",
        "    mse = mean_squared_error(performance_df['y'], performance_df[prediction_col])\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Calculate Mean Absolute Percentage Error (MAPE)\n",
        "    # Avoid division by zero for actual values (y) that are 0\n",
        "    # Handle cases where actuals are zero more gracefully\n",
        "    # Calculate the percentage error only for non-zero actuals\n",
        "    non_zero_actuals = performance_df[performance_df['y'] != 0].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "    if not non_zero_actuals.empty:\n",
        "        # Ensure the prediction column exists in the non_zero_actuals DataFrame before calculating\n",
        "        if prediction_col in non_zero_actuals.columns:\n",
        "            mape = np.mean(np.abs((non_zero_actuals['y'] - non_zero_actuals[prediction_col]) / non_zero_actuals['y'])) * 100\n",
        "        else:\n",
        "            print(f\"Warning: Prediction column '{prediction_col}' not found in non-zero actuals DataFrame for MAPE calculation.\") # Always print warnings\n",
        "            mape = np.nan\n",
        "    else:\n",
        "        mape = np.nan # Or some other indicator that MAPE is not applicable\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n--- Model Evaluation Metrics ---\")\n",
        "        print(f\"Metrics are calculated based on the overall performance for the single store (Butikk_ID) included in the analysis.\")\n",
        "        print(f\"Comparing Actuals ('y') with Predictions ('{prediction_col}') for dates present in the test period (2025 and later).\")\n",
        "        print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "        print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "        print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "        if not np.isnan(mape):\n",
        "            print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
        "        else:\n",
        "             print(\"Mean Absolute Percentage Error (MAPE): N/A (Cannot calculate due to zero actual values or missing prediction column)\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "        print(\"\\n--- Metric Explanations ---\")\n",
        "        print(f\"MAE ({mae:.2f}): The average magnitude of error in sales units. On average, predictions are off by about {mae:.2f} units.\")\n",
        "        print(f\"MSE ({mse:.2f}): The average of the squared errors. Gives more weight to larger errors.\")\n",
        "        print(f\"RMSE ({rmse:.2f}): The square root of MSE, in the same units as sales. Represents the typical magnitude of prediction errors ({rmse:.2f} units).\")\n",
        "        if not np.isnan(mape):\n",
        "            print(f\"MAPE ({mape:.2f}%): The average absolute percentage error. On average, predictions are off by {mape:.2f}% relative to the actual sales for days with non-zero sales.\")\n",
        "        else:\n",
        "            print(\"MAPE: Mean Absolute Percentage Error cannot be calculated when all actual sales values are zero or prediction column is missing.\")\n",
        "        print(\"-----------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fcec957"
      },
      "source": [
        "## Hoveddel av skriptet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "206ce1df",
        "outputId": "e18492de-e9f4-4765-db37-b943fdac188d"
      },
      "outputs": [],
      "source": [
        "# --- Main part of the script ---\n",
        "print(\"Starting the end-to-end data preparation, modeling, and visualization process...\")\n",
        "\n",
        "# Set this variable to True to enable verbose output from helper functions, False to suppress it\n",
        "VerboseBool = True\n",
        "\n",
        "# 1. Prepare sales data using the function\n",
        "print(\"Calling prepare_sales_data function...\")\n",
        "df_prepared = prepare_sales_data('colab/MB salg.xlsx', 'Ark1', verbose=VerboseBool)\n",
        "\n",
        "# 2. Check if df_prepared is not empty\n",
        "if df_prepared.empty:\n",
        "    print(\"\\nError: Sales data preparation failed or returned an empty DataFrame. Cannot proceed.\")\n",
        "else:\n",
        "    print(\"\\nSales data preparation completed successfully.\")\n",
        "\n",
        "    # 3. Add regressors (weekdays, weather, and holidays)\n",
        "    print(\"Calling add_regressors function...\")\n",
        "    # add_regressors now loads and merges weather data and adds holidays internally\n",
        "    df_prepared_with_regressors = add_regressors(df_prepared.copy(), verbose=VerboseBool)\n",
        "\n",
        "\n",
        "    # Check if add_regressors was successful and returned a non-empty DataFrame\n",
        "    if df_prepared_with_regressors.empty:\n",
        "        print(\"\\nError: Adding regressors failed or returned an empty DataFrame. Cannot proceed with modeling.\")\n",
        "    else:\n",
        "        print(\"\\nAdding regressors completed successfully.\")\n",
        "\n",
        "        # 4. Split data using the function\n",
        "        print(\"Calling split_data function...\")\n",
        "        # Use the DataFrame with all regressors for splitting\n",
        "        # split_data does not have a verbose parameter, so no change here\n",
        "        train_df, test_df = split_data(df_prepared_with_regressors)\n",
        "\n",
        "        # 5. Print row counts for confirmation\n",
        "        print(f\"\\nNumber of rows in the training set (before 2025): {len(train_df)}\")\n",
        "        print(f\"Number of rows in the test set (2025 and later): {len(test_df)}\")\n",
        "\n",
        "        if train_df.empty or test_df.empty:\n",
        "            print(\"\\nError: Data splitting resulted in empty training or test sets. Cannot proceed with modeling.\")\n",
        "        else:\n",
        "            # 6. Train Prophet model using the function\n",
        "            print(\"\\nCalling train_prophet_model function...\")\n",
        "            # train_prophet_model does not have a verbose parameter, so no change here\n",
        "            # Note: Holidays should now be handled within add_regressors or passed explicitly if train_prophet_model is updated to accept them\n",
        "            # Assuming train_prophet_model will use regressors already in the DataFrame\n",
        "            prophet_model = train_prophet_model(train_df) # No holidays_df parameter needed if holidays are added as regressors in train_df\n",
        "            print(\"Prophet model trained.\")\n",
        "\n",
        "            # 7. Generate predictions for the test period using the function\n",
        "            print(\"\\nCalling generate_prophet_predictions function...\")\n",
        "            # Ensure test_df contains all necessary regressors for prediction\n",
        "            # generate_prophet_predictions does not have a verbose parameter, so no change here\n",
        "            forecast = generate_prophet_predictions(prophet_model, test_df)\n",
        "            print(\"Predictions generated for the test period.\")\n",
        "\n",
        "            # 8. Print first and last 5 rows of the forecast (specific columns)\n",
        "            print(\"\\nFirst 5 rows of the forecast (ds, yhat, yhat_lower, yhat_upper):\")\n",
        "            display(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())\n",
        "            print(\"\\nLast 5 rows of the forecast (ds, yhat', yhat_lower', yhat_upper'):\")\n",
        "            display(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())\n",
        "\n",
        "            # 9. Visualize the overall results (forecast vs. historical and actuals)\n",
        "            print(\"\\nCalling visualize_prophet_results function (Overall Plot)...\")\n",
        "            visualize_prophet_results(prophet_model, forecast, test_df, verbose=VerboseBool)\n",
        "\n",
        "            # 10. Evaluate the model's accuracy (Original Forecast)\n",
        "            print(\"\\nCalling evaluate_prophet_model function (Original Forecast)...\")\n",
        "            evaluate_prophet_model(test_df, forecast, verbose=VerboseBool)\n",
        "\n",
        "            # 11. Visualize forecast vs. actuals in a separate plot and components (Original Forecast)\n",
        "            print(\"\\nCalling visualize_forecast_vs_actuals function (Original Forecast Separate Plot and Components)...\")\n",
        "            visualize_forecast_vs_actuals(test_df, forecast, verbose=VerboseBool)\n",
        "\n",
        "            # --- Coregation Steps ---\n",
        "            print(\"\\nStarting coregation process...\")\n",
        "\n",
        "            # Step 1: Merge actuals and forecast\n",
        "            print(\"\\nCalling merge_predictions_actuals function...\")\n",
        "            merged_performance_df = merge_predictions_actuals(test_df, forecast)\n",
        "            print(\"Actuals and forecast merged.\")\n",
        "\n",
        "            if not merged_performance_df.empty:\n",
        "                # Step 2: Calculate daily prediction errors\n",
        "                merged_performance_df['prediction_error'] = merged_performance_df['y'] - merged_performance_df['yhat']\n",
        "                print(\"Daily prediction errors calculated.\")\n",
        "\n",
        "                #step 3 make mean_error_df\n",
        "                mean_error_df = calculate_mean_error(merged_performance_df)\n",
        "                print(\"Mean prediction errors calculated.\")\n",
        "\n",
        "                #step 4 sammenslå mean_error og forcast til corected_forecast\n",
        "                merged_performance_df['coregated_yhat'] = forecast['yhat'] + mean_error_df['mean_error']\n",
        "                print(\"Corected forecast generated.\")\n",
        "\n",
        "                # Step 5: Visualize corected forecast vs. actuals and evaluate\n",
        "                print(\"\\nCalling visualize_forecast_vs_actuals function (Corected Forecast Separate Plot and Components)...\")\n",
        "                visualize_forecast_vs_actuals(test_df,merged_performance_df, verbose=VerboseBool)\n",
        "                print(\"\\nCalling evaluate_prophet_model function (Corected Forecast)...\")\n",
        "                evaluate_prophet_model(test_df, merged_performance_df, verbose=VerboseBool)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjBYlJByli6G",
        "outputId": "d5b039f2-9257-4b3f-d50f-1ebaf047ea1d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from datetime import date, timedelta\n",
        "from dateutil.easter import easter # Et nyttig verktøy for å beregne påskedatoer\n",
        "\n",
        "def generate_norwegian_holidays(start_year: int, end_year: int, custom_holidays: pd.DataFrame = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Genererer en Pandas DataFrame med norske helligdager (faste og varierende)\n",
        "    for en gitt årsrekke, inkludert vinduer for effekt før og etter.\n",
        "    Kan også inkludere en valgfri DataFrame med egendefinerte helligdager.\n",
        "\n",
        "    Args:\n",
        "        start_year (int): Startåret for å generere helligdager.\n",
        "        end_year (int): Sluttåret for å generere helligdager (inkluderende).\n",
        "        custom_holidays (pd.DataFrame, optional): En DataFrame med egendefinerte\n",
        "            helligdager med kolonner 'holiday', 'ds', 'lower_window', 'upper_window'.\n",
        "            Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: En DataFrame med kolonner 'holiday', 'ds', 'lower_window', 'upper_window'.\n",
        "                      Helligdagene er sortert etter dato.\n",
        "    \"\"\"\n",
        "\n",
        "    all_holidays_list = []\n",
        "\n",
        "    # Definer vindusparametere som ønsket\n",
        "    lower_window_days = -2\n",
        "    upper_window_days = 1\n",
        "\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        # --- Faste helligdager ---\n",
        "        fixed_holidays = [\n",
        "            (f'{year}-01-01', '1. nyttårsdag'),\n",
        "            (f'{year}-05-01', '1. mai'),\n",
        "            (f'{year}-05-17', 'Grunnlovsdagen'),\n",
        "            (f'{year}-12-25', '1. juledag'),\n",
        "            (f'{year}-12-26', '2. juledag'),\n",
        "        ]\n",
        "\n",
        "        for date_str, name in fixed_holidays:\n",
        "            all_holidays_list.append({\n",
        "                'holiday': name,\n",
        "                'ds': pd.to_datetime(date_str), # These are already Timestamps\n",
        "                'lower_window': lower_window_days,\n",
        "                'upper_window': upper_window_days\n",
        "            })\n",
        "\n",
        "        # --- Varierende helligdager (basert på påske) ---\n",
        "        easter_sunday = easter(year) # Finner dato for 1. påskedag\n",
        "\n",
        "        # Skjærtorsdag: 2 dager før 1. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': 'Skjærtorsdag',\n",
        "            'ds': pd.Timestamp(easter_sunday - timedelta(days=3)), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "        # Langfredag: 1 dag før 1. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': 'Langfredag',\n",
        "            'ds': pd.Timestamp(easter_sunday - timedelta(days=2)), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "        # 1. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': '1. påskedag',\n",
        "            'ds': pd.Timestamp(easter_sunday), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "        # 2. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': '2. påskedag',\n",
        "            'ds': pd.Timestamp(easter_sunday + timedelta(days=1)), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "\n",
        "        # Kristi Himmelfartsdag: 39 dager etter 1. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': 'Kristi Himmelfartsdag',\n",
        "            'ds': pd.Timestamp(easter_sunday + timedelta(days=39)), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "\n",
        "        # 1. pinsedag: 49 dager etter 1. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': '1. pinsedag',\n",
        "            'ds': pd.Timestamp(easter_sunday + timedelta(days=49)), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "        # 2. pinsedag: 50 dager etter 1. påskedag\n",
        "        all_holidays_list.append({\n",
        "            'holiday': '2. pinsedag',\n",
        "            'ds': pd.Timestamp(easter_sunday + timedelta(days=50)), # Convert to Timestamp\n",
        "            'lower_window': lower_window_days,\n",
        "            'upper_window': upper_window_days\n",
        "        })\n",
        "\n",
        "\n",
        "    # Konverter liste av dikter til DataFrame\n",
        "    all_holidays_df = pd.DataFrame(all_holidays_list)\n",
        "\n",
        "    # --- Legg til egendefinerte helligdager hvis de er oppgitt ---\n",
        "    if custom_holidays is not None and not custom_holidays.empty:\n",
        "        # Valider at custom_holidays har de nødvendige kolonnene\n",
        "        required_cols = ['holiday', 'ds', 'lower_window', 'upper_window']\n",
        "        if not all(col in custom_holidays.columns for col in required_cols):\n",
        "             print(\"Warning: custom_holidays DataFrame does not have the required columns. Skipping custom holidays.\")\n",
        "        else:\n",
        "            # Konkatenér de to DataFrames\n",
        "            all_holidays_df = pd.concat([all_holidays_df, custom_holidays], ignore_index=True)\n",
        "            print(f\"Added {len(custom_holidays)} custom holidays.\")\n",
        "\n",
        "\n",
        "    # Sorter etter dato for å holde orden og unngå potensielle problemer\n",
        "    all_holidays_df = all_holidays_df.sort_values(by='ds').reset_index(drop=True)\n",
        "\n",
        "    return all_holidays_df\n",
        "\n",
        "\n",
        "start_year_data = 2020\n",
        "end_year_forecast = 2028\n",
        "\n",
        "# The following lines are just for demonstrating the function's output here:\n",
        "# Define sample custom holidays for demonstration\n",
        "sample_custom_holidays_list = [\n",
        "]\n",
        "if not sample_custom_holidays_list:\n",
        "    print(\"Warning: sample_custom_holidays_list is empty. Skipping custom holidays.\")\n",
        "else:\n",
        "  sample_custom_holidays_df = pd.DataFrame(sample_custom_holidays_list)\n",
        "  sample_custom_holidays_df['ds'] = pd.to_datetime(sample_custom_holidays_df['ds'])\n",
        "\n",
        "\n",
        "norwegian_holidays_with_custom = generate_norwegian_holidays(start_year_data, end_year_forecast)\n",
        "\n",
        "\n",
        "print(\"Genererte norske helligdager med vinduer (inkludert eksempler på egendefinerte):\")\n",
        "print(norwegian_holidays_with_custom.head(20)) # Print more to show custom holidays\n",
        "print(f\"\\nAntall unike helligdager generert: {len(norwegian_holidays_with_custom['holiday'].unique())}\")\n",
        "print(f\"Totalt antall helligdagsdatoer generert: {len(norwegian_holidays_with_custom)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43318f40"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Modified add_regressors to make weather_df and holidays_df optional and call generate_weekday_sequence\n",
        "def add_regressors(df, verbose=True):\n",
        "    \"\"\"\n",
        "    Adds regressor columns, including weekday, weather, and holiday data,\n",
        "    to the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        verbose (bool): If True, print progress messages from helper functions. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with added regressor columns and merged data.\n",
        "                      Returns an empty DataFrame if merging fails critically.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"Warning: Input DataFrame to add_regressors is empty.\") # Always print warnings\n",
        "        return df\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Adding weekday regressors...\")\n",
        "    # Call generate_weekday_sequence to add the 'weekday' and binary columns\n",
        "    df = generate_weekday_sequence(df, verbose=verbose)\n",
        "    if verbose:\n",
        "        print(\"Weekday regressors added.\")\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nLoading and merging weather data...\")\n",
        "    # Call the sub-function to merge weather data if provide\n",
        "    # Pass verbose flag to load_weather_data and merge_weather_data\n",
        "    weather_df = load_weather_data('colab/værtabell.xlsx', verbose=verbose)\n",
        "    df = merge_weather_data(df, weather_df, verbose=verbose)\n",
        "    if verbose:\n",
        "        print(\"Weather data processed and merged.\")\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nAdding school holiday regressors...\")\n",
        "    # Add school holiday columns using the new function\n",
        "    df = legg_til_ferie_kolonner(df, verbose=verbose)\n",
        "    if verbose:\n",
        "        print(\"School holiday regressors added.\")\n",
        "\n",
        "\n",
        "    # Return the final DataFrame with all added regressors\n",
        "    return df\n",
        "\n",
        "\n",
        "# Example usage (will be called from the main script)\n",
        "# print(\"\\nApplying add_regressors function with weather and holiday data...\")\n",
        "# try:\n",
        "#     # Assuming load_weather_data and load_holidays_data have been called\n",
        "#     # df_prepared_with_all_regressors = add_regressors(df_prepared.copy(), weather_df, holidays_df)\n",
        "#     # if not df_prepared_with_all_regressors.empty:\n",
        "#     #     print(\"\\nFirst 5 rows of df_prepared_with_all_regressors:\")\n",
        "#     #     display(df_prepared_with_all_regressors.head())\n",
        "#     #     print(\"\\nInformation about df_prepared_with_all_regressors:\")\n",
        "#     #     display(df_prepared_with_all_regressors.info())\n",
        "#     # else:\n",
        "#     #     print(\"add_regressors function returned an empty DataFrame.\")\n",
        "#     pass # This will be called from the main script now\n",
        "# except NameError:\n",
        "#     print(\"df_prepared, weather_df, or holidays_df is not defined.\")\n",
        "# except Exception as e:\n",
        "#      print(f\"An error occurred during the example usage of add_regressors: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAqzHk_5UTDF"
      },
      "outputs": [],
      "source": [
        "  # --- Define the merge_weather_data sub-function ---\n",
        "  def merge_weather_data(df_to_merge, weather_df, verbose=True):\n",
        "      \"\"\"\n",
        "      Merges the main DataFrame with weather data based on the date.\n",
        "\n",
        "      Args:\n",
        "          df_to_merge (pd.DataFrame): The DataFrame to merge (should have 'ds').\n",
        "          weather_df (pd.DataFrame): The DataFrame with weather data (should have 'ds').\n",
        "          verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: The merged DataFrame, or the original DataFrame if merge fails.\n",
        "      \"\"\"\n",
        "      if verbose:\n",
        "        print(\"\\nAttempting to merge sales data with weather data...\")\n",
        "      if weather_df is None or weather_df.empty:\n",
        "            print(\"Warning: Weather DataFrame provided to merge_weather_data is None or empty. Skipping merge.\") # Always print warnings\n",
        "            return df_to_merge # Return the original DataFrame if no weather data\n",
        "\n",
        "      try:\n",
        "          # Ensure 'ds' in weather_df is also datetime for merging\n",
        "          if 'ds' not in weather_df.columns:\n",
        "                print(\"Error: Weather DataFrame does not have a 'ds' column for merging.\") # Always print errors\n",
        "                return df_to_merge # Return original if no 'ds' in weather_df\n",
        "\n",
        "          if not pd.api.types.is_datetime64_any_dtype(weather_df['ds']):\n",
        "              weather_df['ds'] = pd.to_datetime(weather_df['ds'])\n",
        "\n",
        "          # Identify weather columns to merge (all except 'ds')\n",
        "          weather_cols_to_merge = [col for col in weather_df.columns if col != 'ds']\n",
        "          if not weather_cols_to_merge:\n",
        "              print(\"Warning: No weather columns found in weather_df to merge.\") # Always print warnings\n",
        "              return df_to_merge # Return original if no weather columns\n",
        "\n",
        "          # Perform the merge using a left join to keep all sales dates\n",
        "          merged_df = pd.merge(df_to_merge, weather_df[['ds'] + weather_cols_to_merge], on='ds', how='left')\n",
        "\n",
        "          if merged_df.empty:\n",
        "                print(\"Warning: Merge resulted in an empty DataFrame.\") # Always print warnings\n",
        "          elif verbose:\n",
        "              print(\"Merge successful.\")\n",
        "              print(\"\\nFirst 5 rows of the merged DataFrame:\")\n",
        "              display(merged_df.head())\n",
        "              print(\"\\nLast 5 rows of the merged DataFrame:\")\n",
        "              display(merged_df.tail())\n",
        "              print(\"\\nInformation about the merged DataFrame:\")\n",
        "              display(merged_df.info())\n",
        "\n",
        "\n",
        "          return merged_df\n",
        "      except Exception as e:\n",
        "          print(f\"An error occurred during weather data merge: {e}\") # Always print errors\n",
        "          return df_to_merge # Return original DataFrame on error\n",
        "  # --- End of merge_weather_data sub-function ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b996979"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_weather_data(file_path, verbose=True):\n",
        "    \"\"\"\n",
        "    Loads, processes, and cleans weather data from an Excel file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the Excel file containing weather data.\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The processed DataFrame with relevant columns,\n",
        "                      datetime index, and handled missing values,\n",
        "                      or an empty DataFrame if an error occurred.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 2: Load data, interpreting \"-\" as missing values\n",
        "        # Use header=0 if the first row is the header\n",
        "        weather_df_raw = pd.read_excel(file_path, na_values=\"-\", header=0)\n",
        "        if verbose:\n",
        "            print(f\"Weather data loaded from '{file_path}'.\")\n",
        "\n",
        "        # Step 3: Select relevant columns\n",
        "        relevant_columns = [\n",
        "            'Tid(norsk normaltid)',\n",
        "            'Pent vær (døgn)',\n",
        "            'Nedbør (døgn)',\n",
        "            'Middeltemperatur (døgn)',\n",
        "            'Gjennomsnittlig skydekke (døgn)'\n",
        "        ]\n",
        "        # Check if all relevant columns exist before selecting\n",
        "        missing_cols = [col for col in relevant_columns if col not in weather_df_raw.columns]\n",
        "        if missing_cols:\n",
        "            print(f\"Error: Missing expected columns in weather data: {missing_cols}\") # Always print errors\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        weather_df = weather_df_raw[relevant_columns].copy()\n",
        "        if verbose:\n",
        "            print(\"Selected relevant weather columns.\")\n",
        "\n",
        "        # Step 4: Convert date column to datetime, specifying the correct format\n",
        "        # Based on the error 'time data \"13.12.2021\" doesn't match format \"%m.%d.%Y\"',\n",
        "        # the format might be \"%d.%m.%Y\"\n",
        "        weather_df['Tid(norsk normaltid)'] = pd.to_datetime(weather_df['Tid(norsk normaltid)'], format='%d.%m.%Y', errors='coerce')\n",
        "        if verbose:\n",
        "            print(\"Converted 'Tid(norsk normaltid)' to datetime with specified format.\")\n",
        "\n",
        "        # Drop rows where date conversion failed\n",
        "        weather_df.dropna(subset=['Tid(norsk normaltid)'], inplace=True)\n",
        "\n",
        "        # Rename the date column for consistency with other dataframes\n",
        "        weather_df.rename(columns={'Tid(norsk normaltid)': 'ds'}, inplace=True)\n",
        "\n",
        "\n",
        "        # Step 5: Print missing value counts\n",
        "        if verbose:\n",
        "            print(\"\\nMissing values before handling:\")\n",
        "            print(weather_df.isnull().sum())\n",
        "\n",
        "        # Step 6: Fill missing values in 'Pent vær (døgn)' with 0\n",
        "        if 'Pent vær (døgn)' in weather_df.columns:\n",
        "             weather_df['Pent vær (døgn)'].fillna(0, inplace=True)\n",
        "             if verbose:\n",
        "                print(\"\\nFilled missing values in 'Pent vær (døgn)' with 0.\")\n",
        "        else:\n",
        "            print(\"Warning: 'Pent vær (døgn)' column not found for filling.\") # Always print warnings\n",
        "\n",
        "\n",
        "        # Step 7: Fill missing values in other relevant columns with their mean\n",
        "        cols_to_fill_mean = [\n",
        "            'Nedbør (døgn)',\n",
        "            'Middeltemperatur (døgn)',\n",
        "            'Gjennomsnittlig skydekke (døgn)'\n",
        "        ]\n",
        "        for col in cols_to_fill_mean:\n",
        "            if col in weather_df.columns:\n",
        "                mean_value = weather_df[col].mean()\n",
        "                weather_df[col].fillna(mean_value, inplace=True)\n",
        "                if verbose:\n",
        "                    print(f\"Filled missing values in '{col}' with the mean ({mean_value:.2f}).\")\n",
        "            else:\n",
        "                print(f\"Warning: '{col}' column not found for filling.\") # Always print warnings\n",
        "\n",
        "\n",
        "        # Verify missing values are filled\n",
        "        if verbose:\n",
        "            print(\"\\nMissing values after handling:\")\n",
        "            print(weather_df.isnull().sum())\n",
        "\n",
        "        if not weather_df.empty and verbose:\n",
        "            print(\"\\nProcessed weather DataFrame:\")\n",
        "            display(weather_df.head())\n",
        "            display(weather_df.tail())\n",
        "            print(\"\\nInformation about weather_df:\")\n",
        "            display(weather_df.info())\n",
        "        elif weather_df.empty:\n",
        "             print(\"\\nProcessed weather DataFrame is empty.\") # Always print critical issues\n",
        "\n",
        "\n",
        "        # Step 8: Return the processed DataFrame\n",
        "        return weather_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Weather file '{file_path}' not found.\") # Always print errors\n",
        "        return pd.DataFrame()\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: Missing expected column in weather data processing - {e}\") # Always print errors\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing weather data: {e}\") # Always print errors\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Example usage (will be called in the main script)\n",
        "# print(\"Starting weather data loading and preparation...\")\n",
        "# weather_df = load_weather_data('colab/værtabell.xlsx')\n",
        "#\n",
        "# if not weather_df.empty:\n",
        "#     print(\"\\nWeather data preparation completed successfully.\")\n",
        "# else:\n",
        "#     print(\"\\nWeather data preparation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b292d84a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Modified generate_weekday_sequence to take a DataFrame and add the 'weekday' column\n",
        "def generate_weekday_sequence(df, verbose=True):\n",
        "    \"\"\"\n",
        "    Adds a sequence of weekdays (0-6) and binary weekday columns (is_monday, etc.)\n",
        "    to the DataFrame based on the 'ds' column.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame with a 'ds' column (datetime).\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with the 'weekday' and binary weekday columns added.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"Warning: Input DataFrame to generate_weekday_sequence is empty.\") # Always print warnings\n",
        "        return df\n",
        "\n",
        "    # Ensure the 'ds' column is datetime type\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df['ds']):\n",
        "        df['ds'] = pd.to_datetime(df['ds'])\n",
        "\n",
        "    # Extract the weekday (Monday=0, Sunday=6) from each date\n",
        "    # Corrected: Access .weekday directly from the DatetimeIndex\n",
        "    df['weekday'] = df['ds'].dt.weekday\n",
        "\n",
        "    # Add binary columns for each weekday\n",
        "    weekday_names = ['is_monday', 'is_tuesday', 'is_wednesday', 'is_thursday', 'is_friday', 'is_saturday', 'is_sunday']\n",
        "    for i, day_name in enumerate(weekday_names):\n",
        "        df[day_name] = (df['weekday'] == i).astype(int)\n",
        "\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Added 'weekday' regressor column and binary weekday columns to the DataFrame. First few rows:\")\n",
        "        display(df.head())\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMe8s3Xrwnu5"
      },
      "outputs": [],
      "source": [
        "def legg_til_ferie_kolonner(df: pd.DataFrame, verbose=True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Legger til binære kolonner for skoleferier i Stavanger (2021-2025)\n",
        "    i en dataframe.\n",
        "\n",
        "    Args:\n",
        "        df: En pandas DataFrame som må inneholde en 'ds'-kolonne med datoer.\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        En DataFrame med lagt til feriekolonner.\n",
        "    \"\"\"\n",
        "    # Ensure the 'ds' column is in datetime format\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df['ds']):\n",
        "        df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
        "        # Handle cases where conversion might fail if necessary\n",
        "        df.dropna(subset=['ds'], inplace=True)\n",
        "\n",
        "\n",
        "    # Definerer ferieperiodene for Stavanger\n",
        "    # Merk: Juleferier strekker seg over årsskiftet, så vi behandler dem som '2021/2022', etc.\n",
        "    ferier = {\n",
        "        'sommerferie': [\n",
        "            ('2021-06-25', '2021-08-16'),\n",
        "            ('2022-06-24', '2022-08-17'),\n",
        "            ('2023-06-23', '2023-08-16'),\n",
        "            ('2024-06-20', '2024-08-14'),\n",
        "            ('2025-06-20', '2025-08-13')\n",
        "        ],\n",
        "        'høstferie': [\n",
        "            ('2021-10-11', '2021-10-15'),\n",
        "            ('2022-10-10', '2022-10-14'),\n",
        "            ('2023-10-09', '2023-10-13'),\n",
        "            ('2024-10-07', '2024-10-11')\n",
        "        ],\n",
        "        'juleferie': [\n",
        "            ('2021-12-22', '2022-01-02'),\n",
        "            ('2022-12-22', '2023-01-02'),\n",
        "            ('2023-12-21', '2024-01-03'),\n",
        "            ('2024-12-20', '2025-01-01')\n",
        "        ],\n",
        "        'vinterferie': [\n",
        "            ('2022-02-28', '2022-03-04'),\n",
        "            ('2023-02-27', '2023-03-03'),\n",
        "            ('2024-02-26', '2024-03-01'),\n",
        "            ('2025-02-24', '2025-02-28')\n",
        "        ],\n",
        "        'påskeferie': [\n",
        "            ('2022-04-11', '2022-04-18'),\n",
        "            ('2023-04-03', '2023-04-11'),\n",
        "            ('2024-03-25', '2024-04-01'),\n",
        "            ('2025-04-14', '2025-04-21')\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Initialiserer feriekolonnene med 0\n",
        "    for ferietype in ferier.keys():\n",
        "        df[ferietype] = 0\n",
        "\n",
        "    # Itererer gjennom hver ferietype og setter verdien til 1 for feriedatoer\n",
        "    for ferietype, perioder in ferier.items():\n",
        "        for start_str, slutt_str in perioder:\n",
        "            start_dato = pd.to_datetime(start_str)\n",
        "            slutt_dato = pd.to_datetime(slutt_str)\n",
        "            df.loc[(df['ds'] >= start_dato) & (df['ds'] <= slutt_dato), ferietype] = 1\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Added school holiday columns to the DataFrame.\")\n",
        "        # Optionally display head/info here if verbose is True\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Eksempel på bruk av funksjonen ---\n",
        "# Oppretter en dummy dataframe\n",
        "# data = {\n",
        "#     'ds': ['2023-10-08', '2023-10-10', '2024-02-20', '2024-02-27'],\n",
        "#     'y': [100, 50, 200, 75]\n",
        "# }\n",
        "# dummy_df = pd.DataFrame(data)\n",
        "\n",
        "# Kaller funksjonen for å legge til feriekolonner\n",
        "# df_med_ferier = legg_til_ferie_kolonner(dummy_df.copy())\n",
        "\n",
        "# print(df_med_ferier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ad5327e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def prepare_sales_data_product(file_path, sheet_name, product_row, verbose=True):\n",
        "    \"\"\"\n",
        "    Prepares product sales data from an Excel file for Prophet modeling.\n",
        "    Handles a different file structure: Product ID in column 3, data from row 6.\n",
        "    Retains NaN values for dates without sales.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the Excel file.\n",
        "        sheet_name (str): The name of the sheet to read from.\n",
        "        product_row (int): The row index (0-based) where the product data starts.\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The prepared DataFrame with 'ds', 'y', and 'Product_ID' columns,\n",
        "                      or an empty DataFrame if an error occurred.\n",
        "    \"\"\"\n",
        "    df_full_raw = None\n",
        "    try:\n",
        "        df_full_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
        "        if verbose:\n",
        "            print(f\"Excel file '{file_path}' loaded.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: '{file_path}' not found.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'Product_ID'])\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the Excel file: {e}\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'Product_ID'])\n",
        "\n",
        "    if df_full_raw is not None and not df_full_raw.empty:\n",
        "        # --- Identify date columns and sales data rows ---\n",
        "        # Assuming dates are in the SECOND row (index 1), from column 3 onwards.\n",
        "        # Assuming product data starts from row 6 (index 5) onwards.\n",
        "        # Assuming the first product data is in row 6 (index 5) in the raw data.\n",
        "\n",
        "        # --- Manual Date Range Creation (adapted from prepare_sales_data) ---\n",
        "        # Attempt to read the start and end dates from the raw data if available, otherwise use hardcoded fallbacks.\n",
        "        start_date_from_file = None\n",
        "        end_date_from_file = None\n",
        "\n",
        "        try:\n",
        "            # Attempt to read the start date from the specified cell (B2 -> iloc[1, 1])\n",
        "            raw_start_date_value = df_full_raw.iloc[1, 1]\n",
        "            # Attempt to read the end date from the last date column D2 (iloc[1, 3])\n",
        "            raw_end_date_value = df_full_raw.iloc[1, 3]\n",
        "\n",
        "            # Try to parse these values into datetime objects\n",
        "            if pd.notna(raw_start_date_value):\n",
        "                if isinstance(raw_start_date_value, pd.Timestamp):\n",
        "                    start_date_from_file = raw_start_date_value.strftime('%Y-%m-%d')\n",
        "                else:\n",
        "                    try:\n",
        "                        # Assuming day/month/year format or similar common variations\n",
        "                        start_date_from_file = pd.to_datetime(str(raw_start_date_value).split(' ')[0], errors='coerce').strftime('%Y-%m-%d')\n",
        "                    except:\n",
        "                         print(f\"Warning: Could not parse start date '{raw_start_date_value}'. Using fallback.\") # Always print warnings\n",
        "                         start_date_from_file = '2021-12-09' # Fallback\n",
        "\n",
        "            if pd.notna(raw_end_date_value):\n",
        "                 if isinstance(raw_end_date_value, pd.Timestamp):\n",
        "                    end_date_from_file = raw_end_date_value.strftime('%Y-%m-%d')\n",
        "                 else:\n",
        "                    try:\n",
        "                        # Assuming day/month/year format or similar common variations\n",
        "                        end_date_from_file = pd.to_datetime(str(raw_end_date_value).split(' ')[0], errors='coerce').strftime('%Y-%m-%d')\n",
        "                    except:\n",
        "                         print(f\"Warning: Could not parse end date '{raw_end_date_value}'. Using fallback.\") # Always print warnings\n",
        "                         end_date_from_file = '2025-07-22' # Fallback\n",
        "\n",
        "        except IndexError:\n",
        "            print(\"Warning: Could not access expected date cells. Using fallback dates.\") # Always print warnings\n",
        "            start_date_from_file = '2021-12-09'\n",
        "            end_date_from_file = '2025-07-22'\n",
        "        except Exception as e:\n",
        "             print(f\"An unexpected error occurred while trying to read dates: {e}. Using fallback dates.\") # Always print errors\n",
        "             start_date_from_file = '2021-12-09'\n",
        "             end_date_from_file = '2025-07-22'\n",
        "\n",
        "\n",
        "        start_date_manual = start_date_from_file if start_date_from_file else '2021-12-09'\n",
        "        end_date_manual = end_date_from_file if end_date_from_file else '2025-07-22'\n",
        "\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Creating date range from {start_date_manual} to {end_date_manual}...\")\n",
        "        full_date_range = pd.date_range(start=start_date_manual, end=end_date_manual, freq='D')\n",
        "        full_date_range_df = pd.DataFrame({'ds': full_date_range})\n",
        "        if verbose:\n",
        "            print(f\"Created date range with {len(full_date_range_df)} days.\")\n",
        "\n",
        "\n",
        "        # --- Extract raw sales data for the first product ---\n",
        "        # Product data starts from row 6 (index 5)\n",
        "        if len(df_full_raw) > product_row: # Check that there are enough rows for product data\n",
        "            first_product_row = df_full_raw.iloc[product_row] # Get the row for the first product\n",
        "            selected_product_id = first_product_row.iloc[2] # Product ID is in column 3 (index 2)\n",
        "\n",
        "            # Sales data starts from original column 3 (index 3 in the raw DataFrame)\n",
        "            sales_data_for_selected_product_raw = first_product_row.iloc[3:]\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"Extracted {len(sales_data_for_selected_product_raw)} raw sales data points for product ID {selected_product_id}.\")\n",
        "\n",
        "            # Convert to numeric, set errors to NaN. DO NOT fill NaN with 0 here.\n",
        "            numeric_sales_data = pd.to_numeric(sales_data_for_selected_product_raw, errors='coerce')\n",
        "\n",
        "            # IMPORTANT: Reset the index of the sales data so it matches the date range's RangeIndex\n",
        "            numeric_sales_data = numeric_sales_data.reset_index(drop=True)\n",
        "\n",
        "            # --- Combine date range and sales data ---\n",
        "            if len(numeric_sales_data) != len(full_date_range_df):\n",
        "                print(f\"Critical Warning: Number of sales data points ({len(numeric_sales_data)}) does NOT match the number of days in the date range ({len(full_date_range_df)}). Cannot proceed with data prep.\") # Always print warnings\n",
        "                return pd.DataFrame(columns=['ds', 'y', 'Product_ID'])\n",
        "            else:\n",
        "                df_prepared = pd.DataFrame({\n",
        "                    'ds': full_date_range_df['ds'],\n",
        "                    'y': numeric_sales_data # Use the numeric data with NaNs\n",
        "                })\n",
        "\n",
        "            # --- Add Product_ID ---\n",
        "            df_prepared['Product_ID'] = selected_product_id\n",
        "\n",
        "            # --- Validation ---\n",
        "            if verbose:\n",
        "                print(\"\\nPrepared DataFrame (df_prepared) with manual date range:\")\n",
        "                print(df_prepared.head())\n",
        "                print(\"\\nInformation about df_prepared:\")\n",
        "                df_prepared.info()\n",
        "                print(\"\\nChecking for missing values in df_prepared:\")\n",
        "                print(df_prepared.isnull().sum()) # Show NaN counts\n",
        "\n",
        "\n",
        "            if verbose:\n",
        "                print(\"\\n'df_prepared' for product sales is now ready with manual date range.\")\n",
        "            return df_prepared\n",
        "\n",
        "        else:\n",
        "            print(\"Error: 'df_full_raw' does not have enough rows to extract product data.\") # Always print errors\n",
        "            return pd.DataFrame(columns=['ds', 'y', 'Product_ID'])\n",
        "\n",
        "    else:\n",
        "        print(\"Product data preparation could not be completed due to errors loading the file or empty raw data.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'Product_ID'])\n",
        "\n",
        "\n",
        "# Example usage (replace with your actual file path and sheet name)\n",
        "# print(\"Starting product data preparation using the function...\")\n",
        "# product_df_prepared = prepare_sales_data_product('YourProductSalesFile.xlsx', 'Sheet1') # REPLACE WITH YOUR FILE AND SHEET\n",
        "\n",
        "# if not product_df_prepared.empty:\n",
        "#     print(\"\\nProduct data preparation function completed successfully.\")\n",
        "#     print(\"\\nFirst 5 rows of product_df_prepared:\")\n",
        "#     display(product_df_prepared.head())\n",
        "#     print(\"\\nLast 5 rows of product_df_prepared:\")\n",
        "#     display(product_df_prepared.tail())\n",
        "#     print(\"\\nInformation about product_df_prepared:\")\n",
        "#     display(product_df_prepared.info())\n",
        "# else:\n",
        "#     print(\"\\nProduct data preparation function failed to return a valid DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "f46n0mhRrK1N",
        "outputId": "211eb469-5811-4f3d-adfc-9aafabaa1df7"
      },
      "outputs": [],
      "source": [
        "# Example usage of the new function\n",
        "# Replace 'YourProductSalesFile.xlsx' and 'Sheet1' with your actual file path and sheet name\n",
        "# Added verbose=False to suppress detailed output from this specific call if needed\n",
        "product_df = prepare_sales_data_product('colab/produkter.xlsx', 'Sheet0', 8, verbose=False)\n",
        "\n",
        "if not product_df.empty:\n",
        "    print(\"\\nProduct data loaded successfully:\")\n",
        "    display(product_df.head())\n",
        "    display(product_df.tail())\n",
        "    display(product_df.info())\n",
        "else:\n",
        "    print(\"\\nFailed to load product data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8db95947"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys # Import sys to use sys.exit\n",
        "\n",
        "# 1. Prepare sales data using the function\n",
        "# print(\"Calling prepare_sales_data function...\")\n",
        "# df = prepare_sales_data('colab/MB salg.xlsx', 'Ark1')\n",
        "\n",
        "# if df.empty:\n",
        "#    print(\"Warning: Input DataFrame to add_regressors is empty.\")\n",
        "#    sys.exit(1)\n",
        "\n",
        "# 2. Add weekdays\n",
        "# generate_weekday_sequence now modifies and returns the DataFrame\n",
        "# df = generate_weekday_sequence(df)\n",
        "\n",
        "def aggregate_sales_weekly(df, verbose=True):\n",
        "    \"\"\"\n",
        "    Aggregates sales data weekly, calculating the total sales per week.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Input DataFrame with 'ds' (datetime) and 'y' (sales) columns.\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with 'week_of_year' and 'total_weekly_sales' columns.\n",
        "                      Returns an empty DataFrame if the input is empty or processing fails.\n",
        "    \"\"\"\n",
        "    if df.empty or 'ds' not in df.columns or 'y' not in df.columns:\n",
        "        print(\"Error: Input DataFrame is empty or missing 'ds' or 'y' columns for weekly aggregation.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['year', 'week_of_year', 'total_weekly_sales']) # Added 'year' to returned columns\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Ensure 'ds' is datetime type\n",
        "        if not pd.api.types.is_datetime64_any_dtype(df['ds']):\n",
        "            df['ds'] = pd.to_datetime(df['ds'])\n",
        "\n",
        "        # Extract Year and Week of Year (ISO 8601 standard)\n",
        "        # .dt.isocalendar().week gives the ISO week number (1-53)\n",
        "        # We need week number 0-52, resetting each year.\n",
        "        # We can use strftime('%W') which gives week number 00-53, with week 0 starting on the first Monday of the year.\n",
        "        # Or we can calculate it manually to ensure it aligns with the first week of the dataset.\n",
        "\n",
        "        # Let's try using .dt.isocalendar().week and adjust it.\n",
        "        # ISO week 1 starts with the first Thursday of the year.\n",
        "        # If the first date is in week 49 (as mentioned by the user), ISO week might be suitable or need adjustment.\n",
        "\n",
        "        # A simpler approach for 0-52 week number resetting each year:\n",
        "        # Get the week number using %W (week number of the year, Monday as the first day of week 00)\n",
        "        # Use %W for week number (00-53), Monday as the first day of the week\n",
        "        df_agg = df.copy()\n",
        "        df_agg['year'] = df_agg['ds'].dt.year\n",
        "        df_agg['week_of_year_str'] = df_agg['ds'].dt.strftime('%W')\n",
        "        df_agg['week_of_year'] = df_agg['week_of_year_str'].astype(int)\n",
        "\n",
        "\n",
        "        # Group by Year and Week of Year and sum the sales ('y')\n",
        "        weekly_sales = df_agg.groupby(['year', 'week_of_year'])['y'].sum().reset_index()\n",
        "\n",
        "        # Rename the sales column for clarity\n",
        "        weekly_sales.rename(columns={'y': 'total_weekly_sales'}, inplace=True)\n",
        "\n",
        "        # The user wants week numbers 0-52. %W gives 00-53. This is fine.\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Weekly aggregation completed.\")\n",
        "            display(weekly_sales.head())\n",
        "            display(weekly_sales.tail())\n",
        "\n",
        "\n",
        "        # Return the aggregatet dataframe\n",
        "        return weekly_sales\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during weekly aggregation: {e}\") # Always print errors\n",
        "        return pd.DataFrame(columns=['year', 'week_of_year', 'total_weekly_sales']) # Ensure consistent empty df columns\n",
        "\n",
        "# Example usage (assuming df_prepared_with_regressors exists)\n",
        "# print(\"\\nAggregating sales data weekly...\")\n",
        "# try:\n",
        "#     weekly_aggregated_df = aggregate_sales_weekly(df_prepared_with_regressors.copy())\n",
        "#     print(\"\\nWeekly aggregated data:\")\n",
        "#     display(weekly_aggregated_df.head())\n",
        "#     display(weekly_aggregated_df.tail())\n",
        "#     print(\"\\nInformation about weekly_aggregated_df:\")\n",
        "#     display(weekly_aggregated_df.info())\n",
        "# except NameError:\n",
        "#     print(\"Error: df_prepared_with_regressors is not defined. Run data preparation first.\")\n",
        "# except Exception as e:\n",
        "#      print(f\"An error occurred during example weekly aggregation: {e}\")\n",
        "\n",
        "# weekly_aggregated_df = aggregate_sales_weekly(df_prepared_with_regressors.copy())\n",
        "\n",
        "def calculate_weekly_growth(weekly_aggregated_df, verbose=True):\n",
        "    \"\"\"\n",
        "    Calculates the weekly growth in sales.\n",
        "\n",
        "    Args:\n",
        "        weekly_aggregated_df (pd.DataFrame): A DataFrame with weekly aggregated sales data\n",
        "                                             containing 'year', 'week_of_year', and 'total_weekly_sales' columns.\n",
        "        verbose (bool): If True, print progress messages. Defaults to True.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with 'week_of_year' and 'percentage_growth' columns.\n",
        "                      Returns an empty DataFrame if input is invalid or calculation fails.\n",
        "    \"\"\"\n",
        "    if weekly_aggregated_df.empty or 'year' not in weekly_aggregated_df.columns or 'week_of_year' not in weekly_aggregated_df.columns or 'total_weekly_sales' not in weekly_aggregated_df.columns:\n",
        "        print(\"Error: Input DataFrame is empty or missing required columns for weekly growth calculation.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['week_of_year', 'percentage_growth'])\n",
        "\n",
        "    try:\n",
        "        if verbose:\n",
        "            print(\"Calculating average sales per week across all years...\")\n",
        "        # Calculate average sales per week across all years\n",
        "        average_weekly_sales = weekly_aggregated_df.groupby('week_of_year')['total_weekly_sales'].mean().reset_index()\n",
        "        average_weekly_sales.rename(columns={'total_weekly_sales': 'average_sales'}, inplace=True)\n",
        "\n",
        "        # Sort by week number to ensure correct sequence for growth calculation\n",
        "        average_weekly_sales = average_weekly_sales.sort_values(by='week_of_year').reset_index(drop=True)\n",
        "\n",
        "        # Calculate percentage growth from each week to the next\n",
        "        # To handle the transition from week 52/53 to week 0, we need to append\n",
        "        # the first week's average sales to the end of the DataFrame for calculation.\n",
        "\n",
        "        # Get the average sales for week 0\n",
        "        if 0 in average_weekly_sales['week_of_year'].values:\n",
        "             week_0_sales = average_weekly_sales[average_weekly_sales['week_of_year'] == 0]['average_sales'].iloc[0]\n",
        "             # Append week 0's average sales to the end for calculation from the last week\n",
        "             temp_sales = average_weekly_sales['average_sales'].tolist() + [week_0_sales]\n",
        "\n",
        "             # Calculate percentage change: (Current - Previous) / Previous * 100\n",
        "             # This calculation will produce one extra value for the growth from the last week to week 0.\n",
        "             # The growth for week 0 is the growth from the last week of the previous year to week 0.\n",
        "             # The growth for week N (where N > 0) is the growth from week N-1 to week N.\n",
        "\n",
        "             # Calculate the difference and then percentage change\n",
        "             diff = pd.Series(temp_sales).diff().iloc[1:].tolist() # Difference from previous, dropping the first NaN\n",
        "             previous_sales = pd.Series(temp_sales[:-1]) # The denominator for percentage change\n",
        "\n",
        "             # Avoid division by zero\n",
        "             percentage_growth = []\n",
        "             for i in range(len(diff)):\n",
        "                 if previous_sales.iloc[i] != 0:\n",
        "                     growth = (diff[i] / previous_sales.iloc[i]) * 100\n",
        "                 else:\n",
        "                     # Handle cases where previous week's sales were zero\n",
        "                     # If current sales are also zero, growth is 0%. If current sales are > 0, growth is infinite/undefined.\n",
        "                     # For simplicity, let's assign 0 growth if the previous week was zero.\n",
        "                      growth = 0.0\n",
        "                 percentage_growth.append(growth)\n",
        "\n",
        "        else:\n",
        "             # If week 0 is not in the data, growth calculation from last week to week 0 is not possible in this way\n",
        "             if verbose:\n",
        "                print(\"Warning: Week 0 not found in aggregated data. Skipping calculation of growth from last week to week 0.\")\n",
        "             # Calculate growth only between consecutive weeks present in the data\n",
        "             average_weekly_sales['percentage_growth'] = average_weekly_sales['average_sales'].pct_change() * 100\n",
        "             # Fill the first value (which is NaN after pct_change) with 0 or another appropriate value\n",
        "             average_weekly_sales['percentage_growth'].fillna(0, inplace=True)\n",
        "             percentage_growth = average_weekly_sales['percentage_growth'].tolist() # Use the calculated percentages\n",
        "\n",
        "        # Create the result DataFrame\n",
        "        weekly_growth_df = pd.DataFrame({\n",
        "            'week_of_year': average_weekly_sales['week_of_year'],\n",
        "            'percentage_growth': percentage_growth\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            print(\"\\nWeekly growth calculation completed successfully.\")\n",
        "            print(\"\\nWeekly growth results:\")\n",
        "            display(weekly_growth_df)\n",
        "\n",
        "\n",
        "        return weekly_growth_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during weekly growth calculation: {e}\") # Always print errors\n",
        "        return pd.DataFrame(columns=['week_of_year', 'percentage_growth'])\n",
        "\n",
        "# Test the function with the weekly aggregated data\n",
        "# print(\"Calculating weekly growth...\")\n",
        "# try:\n",
        "#     # Assuming weekly_aggregated_df exists from the previous subtask\n",
        "#     if 'weekly_aggregated_df' in locals() or 'weekly_aggregated_df' in globals():\n",
        "#         weekly_growth_results = calculate_weekly_growth(weekly_aggregated_df.copy())\n",
        "\n",
        "#         if not weekly_growth_results.empty:\n",
        "#             print(\"\\nWeekly growth calculation completed successfully.\")\n",
        "#             print(\"\\nWeekly growth results:\")\n",
        "#             display(weekly_growth_results)\n",
        "#             print(\"\\nInformation about weekly_growth_results:\")\n",
        "#             display(weekly_growth_results.info())\n",
        "#         else:\n",
        "#             print(\"\\nWeekly growth calculation returned an empty DataFrame.\")\n",
        "#     else:\n",
        "#         print(\"Error: weekly_aggregated_df is not defined. Run weekly aggregation first.\")\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during the test of calculate_weekly_growth: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b487ed7"
      },
      "outputs": [],
      "source": [
        "def merge_predictions_actuals(test_df, forecast):\n",
        "    \"\"\"\n",
        "    Combines actual sales data with Prophet forecast and calculates daily error.\n",
        "\n",
        "    Args:\n",
        "        test_df (pd.DataFrame): DataFrame with actual sales ('ds', 'y').\n",
        "        forecast (pd.DataFrame): DataFrame with Prophet forecast ('ds', 'yhat').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Merged DataFrame with 'ds', 'y', and 'yhat' columns.\n",
        "                      Returns an empty DataFrame if merging fails or inputs are invalid.\n",
        "    \"\"\"\n",
        "    if test_df.empty or forecast.empty or 'ds' not in test_df.columns or 'y' not in test_df.columns or 'ds' not in forecast.columns or 'yhat' not in forecast.columns:\n",
        "        print(\"Error: Input DataFrames are empty or missing required columns for merging.\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'yhat'])\n",
        "\n",
        "    try:\n",
        "        # Ensure 'ds' columns are datetime type for merging\n",
        "        if not pd.api.types.is_datetime64_any_dtype(test_df['ds']):\n",
        "            test_df['ds'] = pd.to_datetime(test_df['ds'], errors='coerce')\n",
        "            test_df.dropna(subset=['ds'], inplace=True) # Drop rows where conversion failed\n",
        "\n",
        "        if not pd.api.types.is_datetime64_any_dtype(forecast['ds']):\n",
        "             forecast['ds'] = pd.to_datetime(forecast['ds'], errors='coerce')\n",
        "             forecast.dropna(subset=['ds'], inplace=True) # Drop rows where conversion failed\n",
        "\n",
        "\n",
        "        # Merge actuals with forecast based on date\n",
        "        # Use an inner join to keep only dates present in both DataFrames\n",
        "        merged_df = pd.merge(test_df[['ds', 'y']], forecast[['ds', 'yhat']], on='ds', how='inner')\n",
        "\n",
        "        if merged_df.empty:\n",
        "            print(\"Warning: Merge resulted in an empty DataFrame. No overlapping dates between test_df and forecast.\") # Always print warnings\n",
        "\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during merging test_df and forecast: {e}\") # Always print errors\n",
        "        return pd.DataFrame(columns=['ds', 'y', 'yhat'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "779d8ba5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_mean_error(merged_performance_df):\n",
        "    \"\"\"\n",
        "    Calculates the mean prediction error for each date based on the same weekday\n",
        "    in the preceding three weeks (ds-7, ds-14, ds-21). Sets mean_error to 0 for\n",
        "    the first 21 days.\n",
        "\n",
        "    Args:\n",
        "        merged_performance_df (pd.DataFrame): DataFrame containing 'ds' and 'prediction_error'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'ds' and the calculated 'mean_error' column.\n",
        "                      Returns an empty DataFrame if input is invalid.\n",
        "    \"\"\"\n",
        "    if merged_performance_df.empty or 'ds' not in merged_performance_df.columns or 'prediction_error' not in merged_performance_df.columns:\n",
        "        print(\"Error: Input DataFrame is empty or missing 'ds' or 'prediction_error' columns for mean error calculation.\")\n",
        "        return pd.DataFrame(columns=['ds', 'mean_error'])\n",
        "\n",
        "    # Ensure 'ds' is datetime and sort by date\n",
        "    if not pd.api.types.is_datetime64_any_dtype(merged_performance_df['ds']):\n",
        "        merged_performance_df['ds'] = pd.to_datetime(merged_performance_df['ds'])\n",
        "    merged_performance_df = merged_performance_df.sort_values(by='ds').reset_index(drop=True)\n",
        "\n",
        "    # Initialize 'mean_error' column with 0\n",
        "    merged_performance_df['mean_error'] = 0.0\n",
        "\n",
        "    # Calculate mean error for dates after the first 21 days\n",
        "    # Iterate through the DataFrame starting from the 22nd day (index 21)\n",
        "    for i in range(21, len(merged_performance_df)):\n",
        "        current_date = merged_performance_df.loc[i, 'ds']\n",
        "        errors_to_average = []\n",
        "\n",
        "        # Look back at the same weekday in the previous 3 weeks\n",
        "        for j in range(1, 4): # Look back 1, 2, and 3 weeks\n",
        "            previous_date = current_date - pd.Timedelta(days=7 * j)\n",
        "\n",
        "            # Find the row for the previous date\n",
        "            previous_row = merged_performance_df[merged_performance_df['ds'] == previous_date]\n",
        "\n",
        "            if not previous_row.empty:\n",
        "                # Add the prediction error from the previous date\n",
        "                errors_to_average.append(previous_row['prediction_error'].iloc[0]) # Use .iloc[0] to get the value\n",
        "\n",
        "        # Calculate the average error if errors were found\n",
        "        if errors_to_average:\n",
        "            merged_performance_df.loc[i, 'mean_error'] = sum(errors_to_average) / len(errors_to_average)\n",
        "        # If no errors were found in the lookback window (e.g., early dates), mean_error remains 0 (initialized)\n",
        "\n",
        "\n",
        "    # Return DataFrame with 'ds' and 'mean_error'\n",
        "    return merged_performance_df[['ds', 'mean_error']].copy()\n",
        "\n",
        "# Example Usage (replace with your actual merged_performance_df)\n",
        "# Assuming merged_performance_df is available from previous steps and has 'ds' and 'prediction_error'\n",
        "# try:\n",
        "#     if 'merged_performance_df' in locals() or 'merged_performance_df' in globals():\n",
        "#          mean_error_df_result = calculate_mean_error(merged_performance_df.copy())\n",
        "#\n",
        "#          if not mean_error_df_result.empty:\n",
        "#              print(\"\\nMean error calculation completed successfully.\")\n",
        "#              print(\"\\nMean error DataFrame (first 30 rows):\")\n",
        "#              display(mean_error_df_result.head(30)) # Display more rows to see non-zero errors\n",
        "#              print(\"\\nMean error DataFrame (tail):\")\n",
        "#              display(mean_error_df_result.tail())\n",
        "#              print(\"\\nInformation about mean_error_df_result:\")\n",
        "#              display(mean_error_df_result.info())\n",
        "#          else:\n",
        "#              print(\"\\nMean error calculation returned an empty DataFrame.\")\n",
        "#     else:\n",
        "#         print(\"Error: merged_performance_df is not defined. Run merging step first.\")\n",
        "#\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred during the test of calculate_mean_error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
